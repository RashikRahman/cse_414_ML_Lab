{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11d8bdb1-03df-411d-bfd1-e6fd8185cd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad0aecc-76dd-4ccc-bd98-289df293b578",
   "metadata": {},
   "source": [
    "# Statistial Analysis \n",
    "\n",
    "Topics:\n",
    "\n",
    " - Normalization (Min-Max)\n",
    " - Mean, Median, Mode\n",
    " - Standard Deviation + ±3σ rule (outlier idea)\n",
    " - Standardization (Z-score)\n",
    " - IQR (Interquartile Range) outliers\n",
    " - Skewness, Kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7531e41a-f0a7-4e0f-824f-30b190a5f17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 100\n",
      "First 10: [61.13686093 38.0447419  38.52285928 30.46957862 46.78273561 63.84693092\n",
      " 41.66508746 55.56235582 52.80131591 49.50995079]\n"
     ]
    }
   ],
   "source": [
    "# We'll create a feature vector with a few outliers so we can see:\n",
    "# - mean vs median difference\n",
    "# - ±3σ and IQR outlier detection\n",
    "# - skewness/kurtosis behavior\n",
    "\n",
    "x = np.concatenate([\n",
    "    np.random.normal(loc=50, scale=10, size=95),  # \"typical\" values\n",
    "    np.array([120, 130, 140, 5, 8])               # outliers (high + low)\n",
    "])\n",
    "\n",
    "print(\"Count:\", x.size)\n",
    "print(\"First 10:\", x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00e873a0-e459-4268-85d1-3c8196026bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/i373-Vc2d4o?si=g33RiXfjTcZHKD5d\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/i373-Vc2d4o?si=g33RiXfjTcZHKD5d\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af14c296-6f65-4013-8b60-4bb3d0a4c921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean  : 51.578381392150874\n",
      "Median: 50.71083036266927\n",
      "Mode  : 5.0 (Note: mode is not very meaningful for continuous random data)\n"
     ]
    }
   ],
   "source": [
    "# Mean   = average; sensitive to outliers, so it doesn't give accurate analysis\n",
    "# Median = middle value after sorting; robust to outliers\n",
    "# Mode   = most frequent value; useful for categorical/discrete data\n",
    "\n",
    "mean_x = np.mean(x)\n",
    "median_x = np.median(x)\n",
    "\n",
    "# Mode in pure NumPy (works best for discrete values)\n",
    "vals, counts = np.unique(x, return_counts=True)\n",
    "mode_x = vals[np.argmax(counts)]  # for continuous random data, mode often isn't meaningful\n",
    "\n",
    "print(\"Mean  :\", mean_x)\n",
    "print(\"Median:\", median_x)\n",
    "print(\"Mode  :\", mode_x, \"(Note: mode is not very meaningful for continuous random data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23e08d10-bb04-433e-8a86-0ccf8a1420b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Std dev: 17.659886684062034\n",
      "3σ range: (-1.4012786600352314, 104.55804144433698)\n",
      "Outliers by ±3σ rule: [120. 130. 140.]\n",
      "Outlier count: 3\n"
     ]
    }
   ],
   "source": [
    "# Std dev (σ) measures typical spread around the mean.\n",
    "# ±3σ rule (empirical rule): for roughly normal data, ~99.7% points lie within mean ± 3σ.\n",
    "# So values outside mean ± 3σ are often treated as potential outliers.\n",
    "\n",
    "std_x = np.std(x, ddof=0)  # population std (ddof=0). For sample std, use ddof=1.\n",
    "\n",
    "lower_3s = mean_x - 3 * std_x\n",
    "upper_3s = mean_x + 3 * std_x\n",
    "\n",
    "outliers_3s = x[(x < lower_3s) | (x > upper_3s)]\n",
    "\n",
    "print(\"Std dev:\", std_x)\n",
    "print(\"3σ range:\", (lower_3s, upper_3s))\n",
    "print(\"Outliers by ±3σ rule:\", outliers_3s)\n",
    "print(\"Outlier count:\", outliers_3s.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938b0d0c-ed70-4d8e-b6b0-cf72a1f4ad44",
   "metadata": {},
   "source": [
    "## Min–Max Normalization\n",
    "\n",
    "$x_{\\text{norm}} = \\frac{x - x_{\\min}}{x_{\\max} - x_{\\min}}$\n",
    "\n",
    "## Standardization (Z-score)\n",
    "\n",
    "$z = \\frac{x - \\mu}{\\sigma}$\n",
    "\n",
    "where $\\mu$ is the mean and $\\sigma$ is the standard deviation.\n",
    "\n",
    "## Cons of Min–Max and how Standardization helps\n",
    "\n",
    "**Cons of Min–Max**\n",
    "\n",
    "Very sensitive to outliers: if one value is extremely large/small, $x_{\\max}$ or $x_{\\min}$ becomes extreme, and most normal values get squeezed into a tiny range near 0 or 1.\n",
    "\n",
    "Range depends on the dataset: when new data arrives with a new max/min, the scaling changes, so the same value can map differently across datasets.\n",
    "\n",
    "**How Standardization helps**\n",
    "\n",
    "Less dominated by extreme min/max: it scales using $\\mu$ and $\\sigma$, so a single outlier usually affects scaling less than directly setting the entire range.\n",
    "\n",
    "Produces comparable feature scales: features become centered at 0 with unit variance, which often helps gradient-based models (e.g., logistic regression, SVM, neural nets) learn faster and more stably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf00179f-6cb1-4594-8a3e-b4c3eaabbab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min, Max: 5.0 140.0\n",
      "Normalized range: (0.0, 1.0)\n",
      "First 5 normalized: [0.4158286  0.24477587 0.24831748 0.18866355 0.30950175]\n"
     ]
    }
   ],
   "source": [
    "# Normalization (Min-Max): rescales data into [0, 1]\n",
    "# Formula: x_norm = (x - min(x)) / (max(x) - min(x))\n",
    "# Useful when features have different units/ranges and you want them comparable.\n",
    "# Note: very sensitive to outliers because min/max can be extreme.\n",
    "\n",
    "x_min, x_max = x.min(), x.max()\n",
    "x_norm = (x - x_min) / (x_max - x_min)\n",
    "\n",
    "print(\"Min, Max:\", x_min, x_max)\n",
    "print(\"Normalized range:\", (x_norm.min(), x_norm.max()))\n",
    "print(\"First 5 normalized:\", x_norm[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c32e9aa-040b-42f7-9e50-b86a9e114eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized mean ~ 4.973799150320702e-16\n",
      "Standardized std  ~ 0.9999999994337448\n",
      "First 5 standardized: [ 0.54125373 -0.76634917 -0.73927553 -1.19529661 -0.27155586]\n"
     ]
    }
   ],
   "source": [
    "# Standardization: makes data have mean ~0 and std ~1\n",
    "# Formula: z = (x - mean) / std\n",
    "# Helpful for models sensitive to scale (e.g., gradient descent, SVM, KNN, PCA).\n",
    "\n",
    "x_z = (x - mean_x) / (std_x + 1e-8)  # epsilon avoids divide-by-zero\n",
    "\n",
    "print(\"Standardized mean ~\", x_z.mean())\n",
    "print(\"Standardized std  ~\", x_z.std())\n",
    "print(\"First 5 standardized:\", x_z[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a30a29f-fa1d-4f13-8c27-415d6cd3f671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1, Median, Q3: 43.647444338938 50.71083036266927 56.82280165879751\n",
      "IQR: 13.175357319859508\n",
      "IQR range: (23.88440835914874, 76.58583763858677)\n",
      "Outliers by IQR: [ 17.08180503 120.         130.         140.           5.\n",
      "   8.        ]\n",
      "Outlier count: 6\n"
     ]
    }
   ],
   "source": [
    "# Quartiles:\n",
    "# Q1 = 25th percentile\n",
    "# Q2 = 50th percentile (median)\n",
    "# Q3 = 75th percentile\n",
    "#\n",
    "# IQR = Q3 - Q1 (spread of middle 50% of data)\n",
    "#-----------q1--------/--------q2-------/---------q3-------/----------q4--------/\n",
    "# IQR outlier rule (common robust rule):\n",
    "# lower = Q1 - 1.5*IQR\n",
    "# upper = Q3 + 1.5*IQR\n",
    "# Values outside are potential outliers (more robust than ±3σ for skewed data).\n",
    "\n",
    "Q1 = np.percentile(x, 25)\n",
    "Q3 = np.percentile(x, 75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_iqr = Q1 - 1.5 * IQR\n",
    "upper_iqr = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers_iqr = x[(x < lower_iqr) | (x > upper_iqr)]\n",
    "\n",
    "print(\"Q1, Median, Q3:\", Q1, median_x, Q3)\n",
    "print(\"IQR:\", IQR)\n",
    "print(\"IQR range:\", (lower_iqr, upper_iqr))\n",
    "print(\"Outliers by IQR:\", outliers_iqr)\n",
    "print(\"Outlier count:\", outliers_iqr.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1807d86d-f88f-4b84-b448-2e21eaa1e541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean                      51.578381\n",
       "median                    50.710830\n",
       "std                       17.659887\n",
       "min                        5.000000\n",
       "max                      140.000000\n",
       "Q1                        43.647444\n",
       "Q3                        56.822802\n",
       "IQR                       13.175357\n",
       "outliers_3sigma_count      3.000000\n",
       "outliers_iqr_count         6.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When to use what (quick rules):\n",
    "# - Mean/Std: good for roughly normal numeric features (but sensitive to outliers)\n",
    "# - Median/IQR: robust summaries when outliers/skew exist\n",
    "# - Min-Max normalization: when you want [0,1] scaling (but outlier-sensitive)\n",
    "# - Z-score standardization: common default for many ML algorithms\n",
    "# - ±3σ rule: simple outlier rule for near-normal data\n",
    "# - IQR rule: robust outlier rule for skewed/non-normal data\n",
    "\n",
    "summary = {\n",
    "    \"mean\": mean_x,\n",
    "    \"median\": median_x,\n",
    "    \"std\": std_x,\n",
    "    \"min\": x_min,\n",
    "    \"max\": x_max,\n",
    "    \"Q1\": Q1,\n",
    "    \"Q3\": Q3,\n",
    "    \"IQR\": IQR,\n",
    "    \"outliers_3sigma_count\": int(outliers_3s.size),\n",
    "    \"outliers_iqr_count\": int(outliers_iqr.size),\n",
    "}\n",
    "pd.Series(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
